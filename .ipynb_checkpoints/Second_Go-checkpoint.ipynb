{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import pandas as pd\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = '/media/tyler/slowdata/models/keras_vgg_16'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = '/home/tyler/data/kaggle/dog_breed/train/'\n",
    "ordered_train_folder = \"/home/tyler/data/kaggle/dog_breed/train_ordered/\"\n",
    "test_data_dir = '/home/tyler/data/kaggle/dog_breed/test/'\n",
    "labels = '/home/tyler/data/kaggle/dog_breed/labels.csv'\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "nb_train_samples = 10222\n",
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False,\n",
    "                          input_shape=(img_width, img_height, 3), classes=120)\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(120, activation='softmax'))\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 120)               6453624   \n",
      "=================================================================\n",
      "Total params: 21,168,312\n",
      "Trainable params: 6,453,624\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 classes\n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_csv(labels)\n",
    "labels_df = labels_df.set_index('id')\n",
    "class_names = labels_df['breed'].unique()\n",
    "n_classes = len(class_names)\n",
    "index_to_classes = {i:c for i, c in enumerate(class_names)}\n",
    "classes_to_index = {c:i for i,c in index_to_classes.items()}\n",
    "print(\"{} classes\".format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ys = []\n",
    "all_Xs = []\n",
    "for img_path in os.listdir(train_data_dir):\n",
    "    class_name = img_path.split(\".\")[0]\n",
    "    y = classes_to_index[labels_df.loc[class_name]['breed']]\n",
    "    img = image.load_img(train_data_dir + img_path, \n",
    "                         target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    all_ys.append(y)\n",
    "    all_Xs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_Xs)\n",
    "X = X.reshape(-1, img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(all_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=1000, callbacks=[<keras.ca..., validation_data=(array([[[..., steps_per_epoch=159)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7841 - acc: 0.0102Epoch 00000: val_loss improved from inf to 15.74207, saving model to ./tmp/weights.00.hdf5\n",
      "159/159 [==============================] - 53s - loss: 4.7839 - acc: 0.0103 - val_loss: 15.7421 - val_acc: 0.0100\n",
      "Epoch 2/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7799 - acc: 0.0112Epoch 00001: val_loss improved from 15.74207 to 15.74063, saving model to ./tmp/weights.01.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.7797 - acc: 0.0112 - val_loss: 15.7406 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7800 - acc: 0.0118Epoch 00002: val_loss improved from 15.74063 to 15.72017, saving model to ./tmp/weights.02.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.7803 - acc: 0.0117 - val_loss: 15.7202 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7748 - acc: 0.0122Epoch 00003: val_loss improved from 15.72017 to 15.70737, saving model to ./tmp/weights.03.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.7748 - acc: 0.0122 - val_loss: 15.7074 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7694 - acc: 0.0140Epoch 00004: val_loss improved from 15.70737 to 15.68289, saving model to ./tmp/weights.04.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.7697 - acc: 0.0140 - val_loss: 15.6829 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7704 - acc: 0.0115Epoch 00005: val_loss improved from 15.68289 to 15.65679, saving model to ./tmp/weights.05.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.7706 - acc: 0.0116 - val_loss: 15.6568 - val_acc: 0.0100\n",
      "Epoch 7/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7654 - acc: 0.0134Epoch 00006: val_loss did not improve\n",
      "159/159 [==============================] - 51s - loss: 4.7655 - acc: 0.0136 - val_loss: 15.6579 - val_acc: 0.0200\n",
      "Epoch 8/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7597 - acc: 0.0141Epoch 00007: val_loss improved from 15.65679 to 15.62583, saving model to ./tmp/weights.07.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.7596 - acc: 0.0140 - val_loss: 15.6258 - val_acc: 0.0200\n",
      "Epoch 9/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7574 - acc: 0.0148Epoch 00008: val_loss did not improve\n",
      "159/159 [==============================] - 51s - loss: 4.7571 - acc: 0.0148 - val_loss: 15.6349 - val_acc: 0.0200\n",
      "Epoch 10/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7493 - acc: 0.0166Epoch 00009: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.7491 - acc: 0.0167 - val_loss: 15.6517 - val_acc: 0.0200\n",
      "Epoch 11/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7433 - acc: 0.0158Epoch 00010: val_loss improved from 15.62583 to 15.61390, saving model to ./tmp/weights.10.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.7432 - acc: 0.0157 - val_loss: 15.6139 - val_acc: 0.0200\n",
      "Epoch 12/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7419 - acc: 0.0178Epoch 00011: val_loss improved from 15.61390 to 15.58680, saving model to ./tmp/weights.11.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.7423 - acc: 0.0177 - val_loss: 15.5868 - val_acc: 0.0100\n",
      "Epoch 13/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7354 - acc: 0.0171Epoch 00012: val_loss improved from 15.58680 to 15.57012, saving model to ./tmp/weights.12.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.7357 - acc: 0.0170 - val_loss: 15.5701 - val_acc: 0.0100\n",
      "Epoch 14/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7311 - acc: 0.0169Epoch 00013: val_loss improved from 15.57012 to 15.53229, saving model to ./tmp/weights.13.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.7309 - acc: 0.0170 - val_loss: 15.5323 - val_acc: 0.0100\n",
      "Epoch 15/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7201 - acc: 0.0210Epoch 00014: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.7203 - acc: 0.0210 - val_loss: 15.5341 - val_acc: 0.0100\n",
      "Epoch 16/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7134 - acc: 0.0211Epoch 00015: val_loss improved from 15.53229 to 15.51020, saving model to ./tmp/weights.15.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.7137 - acc: 0.0213 - val_loss: 15.5102 - val_acc: 0.0100\n",
      "Epoch 17/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7118 - acc: 0.0200Epoch 00016: val_loss improved from 15.51020 to 15.50655, saving model to ./tmp/weights.16.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.7120 - acc: 0.0200 - val_loss: 15.5065 - val_acc: 0.0100\n",
      "Epoch 18/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6993 - acc: 0.0242Epoch 00017: val_loss improved from 15.50655 to 15.47441, saving model to ./tmp/weights.17.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6989 - acc: 0.0244 - val_loss: 15.4744 - val_acc: 0.0100\n",
      "Epoch 19/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.7009 - acc: 0.0249Epoch 00018: val_loss improved from 15.47441 to 15.46234, saving model to ./tmp/weights.18.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.7005 - acc: 0.0249 - val_loss: 15.4623 - val_acc: 0.0100\n",
      "Epoch 20/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6896 - acc: 0.0231Epoch 00019: val_loss improved from 15.46234 to 15.42914, saving model to ./tmp/weights.19.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6897 - acc: 0.0232 - val_loss: 15.4291 - val_acc: 0.0100\n",
      "Epoch 21/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6836 - acc: 0.0242Epoch 00020: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.6831 - acc: 0.0243 - val_loss: 15.4488 - val_acc: 0.0100\n",
      "Epoch 22/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6774 - acc: 0.0259Epoch 00021: val_loss improved from 15.42914 to 15.40577, saving model to ./tmp/weights.21.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6771 - acc: 0.0259 - val_loss: 15.4058 - val_acc: 0.0100\n",
      "Epoch 23/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6642 - acc: 0.0284Epoch 00022: val_loss improved from 15.40577 to 15.40241, saving model to ./tmp/weights.22.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6641 - acc: 0.0285 - val_loss: 15.4024 - val_acc: 0.0100\n",
      "Epoch 24/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6607 - acc: 0.0297Epoch 00023: val_loss improved from 15.40241 to 15.34572, saving model to ./tmp/weights.23.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6606 - acc: 0.0296 - val_loss: 15.3457 - val_acc: 0.0100\n",
      "Epoch 25/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6499 - acc: 0.0331Epoch 00024: val_loss improved from 15.34572 to 15.32610, saving model to ./tmp/weights.24.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6496 - acc: 0.0331 - val_loss: 15.3261 - val_acc: 0.0200\n",
      "Epoch 26/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6461 - acc: 0.0295Epoch 00025: val_loss improved from 15.32610 to 15.32089, saving model to ./tmp/weights.25.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6458 - acc: 0.0297 - val_loss: 15.3209 - val_acc: 0.0200\n",
      "Epoch 27/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6320 - acc: 0.0329Epoch 00026: val_loss improved from 15.32089 to 15.26868, saving model to ./tmp/weights.26.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6322 - acc: 0.0330 - val_loss: 15.2687 - val_acc: 0.0200\n",
      "Epoch 28/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6242 - acc: 0.0325Epoch 00027: val_loss improved from 15.26868 to 15.25111, saving model to ./tmp/weights.27.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 52s - loss: 4.6241 - acc: 0.0324 - val_loss: 15.2511 - val_acc: 0.0200\n",
      "Epoch 29/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6225 - acc: 0.0350Epoch 00028: val_loss improved from 15.25111 to 15.16586, saving model to ./tmp/weights.28.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6229 - acc: 0.0350 - val_loss: 15.1659 - val_acc: 0.0200\n",
      "Epoch 30/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6097 - acc: 0.0360Epoch 00029: val_loss improved from 15.16586 to 15.15436, saving model to ./tmp/weights.29.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.6095 - acc: 0.0358 - val_loss: 15.1544 - val_acc: 0.0200\n",
      "Epoch 31/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.6067 - acc: 0.0339Epoch 00030: val_loss improved from 15.15436 to 15.10259, saving model to ./tmp/weights.30.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.6066 - acc: 0.0343 - val_loss: 15.1026 - val_acc: 0.0200\n",
      "Epoch 32/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5912 - acc: 0.0388Epoch 00031: val_loss improved from 15.10259 to 15.05605, saving model to ./tmp/weights.31.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.5907 - acc: 0.0389 - val_loss: 15.0560 - val_acc: 0.0200\n",
      "Epoch 33/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5831 - acc: 0.0407Epoch 00032: val_loss improved from 15.05605 to 14.96638, saving model to ./tmp/weights.32.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.5829 - acc: 0.0411 - val_loss: 14.9664 - val_acc: 0.0200\n",
      "Epoch 34/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5671 - acc: 0.0365Epoch 00033: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.5675 - acc: 0.0365 - val_loss: 14.9726 - val_acc: 0.0300\n",
      "Epoch 35/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5727 - acc: 0.0432Epoch 00034: val_loss improved from 14.96638 to 14.95311, saving model to ./tmp/weights.34.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.5724 - acc: 0.0431 - val_loss: 14.9531 - val_acc: 0.0300\n",
      "Epoch 36/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5610 - acc: 0.0426Epoch 00035: val_loss improved from 14.95311 to 14.76254, saving model to ./tmp/weights.35.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.5612 - acc: 0.0423 - val_loss: 14.7625 - val_acc: 0.0300\n",
      "Epoch 37/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5482 - acc: 0.0426Epoch 00036: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.5481 - acc: 0.0426 - val_loss: 14.8019 - val_acc: 0.0300\n",
      "Epoch 38/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5431 - acc: 0.0464Epoch 00037: val_loss improved from 14.76254 to 14.74648, saving model to ./tmp/weights.37.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.5429 - acc: 0.0462 - val_loss: 14.7465 - val_acc: 0.0300\n",
      "Epoch 39/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5273 - acc: 0.0499Epoch 00038: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.5271 - acc: 0.0499 - val_loss: 14.7754 - val_acc: 0.0300\n",
      "Epoch 40/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5188 - acc: 0.0461Epoch 00039: val_loss improved from 14.74648 to 14.74514, saving model to ./tmp/weights.39.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.5190 - acc: 0.0459 - val_loss: 14.7451 - val_acc: 0.0300\n",
      "Epoch 41/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.5049 - acc: 0.0506Epoch 00040: val_loss improved from 14.74514 to 14.68118, saving model to ./tmp/weights.40.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.5048 - acc: 0.0504 - val_loss: 14.6812 - val_acc: 0.0300\n",
      "Epoch 42/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4969 - acc: 0.0493Epoch 00041: val_loss improved from 14.68118 to 14.66834, saving model to ./tmp/weights.41.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.4968 - acc: 0.0495 - val_loss: 14.6683 - val_acc: 0.0300\n",
      "Epoch 43/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4921 - acc: 0.0498Epoch 00042: val_loss did not improve\n",
      "159/159 [==============================] - 51s - loss: 4.4921 - acc: 0.0497 - val_loss: 14.7029 - val_acc: 0.0400\n",
      "Epoch 44/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4839 - acc: 0.0542Epoch 00043: val_loss improved from 14.66834 to 14.60469, saving model to ./tmp/weights.43.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.4843 - acc: 0.0543 - val_loss: 14.6047 - val_acc: 0.0400\n",
      "Epoch 45/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4749 - acc: 0.0532Epoch 00044: val_loss improved from 14.60469 to 14.58174, saving model to ./tmp/weights.44.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.4745 - acc: 0.0530 - val_loss: 14.5817 - val_acc: 0.0400\n",
      "Epoch 46/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4568 - acc: 0.0554Epoch 00045: val_loss improved from 14.58174 to 14.54697, saving model to ./tmp/weights.45.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.4568 - acc: 0.0554 - val_loss: 14.5470 - val_acc: 0.0400\n",
      "Epoch 47/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4487 - acc: 0.0561Epoch 00046: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.4494 - acc: 0.0559 - val_loss: 14.5606 - val_acc: 0.0500\n",
      "Epoch 48/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4391 - acc: 0.0603Epoch 00047: val_loss improved from 14.54697 to 14.54636, saving model to ./tmp/weights.47.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.4388 - acc: 0.0604 - val_loss: 14.5464 - val_acc: 0.0500\n",
      "Epoch 49/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4262 - acc: 0.0582Epoch 00048: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.4262 - acc: 0.0582 - val_loss: 14.5780 - val_acc: 0.0500\n",
      "Epoch 50/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4246 - acc: 0.0557Epoch 00049: val_loss improved from 14.54636 to 14.52238, saving model to ./tmp/weights.49.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.4242 - acc: 0.0561 - val_loss: 14.5224 - val_acc: 0.0400\n",
      "Epoch 51/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4045 - acc: 0.0611Epoch 00050: val_loss improved from 14.52238 to 14.51197, saving model to ./tmp/weights.50.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.4039 - acc: 0.0611 - val_loss: 14.5120 - val_acc: 0.0500\n",
      "Epoch 52/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.4026 - acc: 0.0570Epoch 00051: val_loss improved from 14.51197 to 14.49582, saving model to ./tmp/weights.51.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.4019 - acc: 0.0571 - val_loss: 14.4958 - val_acc: 0.0300\n",
      "Epoch 53/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.3890 - acc: 0.0613Epoch 00052: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.3888 - acc: 0.0614 - val_loss: 14.5465 - val_acc: 0.0400\n",
      "Epoch 54/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.3839 - acc: 0.0640Epoch 00053: val_loss improved from 14.49582 to 14.49231, saving model to ./tmp/weights.53.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.3836 - acc: 0.0640 - val_loss: 14.4923 - val_acc: 0.0400\n",
      "Epoch 55/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.3730 - acc: 0.0648Epoch 00054: val_loss improved from 14.49231 to 14.45313, saving model to ./tmp/weights.54.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.3731 - acc: 0.0647 - val_loss: 14.4531 - val_acc: 0.0400\n",
      "Epoch 56/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.3558 - acc: 0.0684Epoch 00055: val_loss improved from 14.45313 to 14.41238, saving model to ./tmp/weights.55.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.3563 - acc: 0.0687 - val_loss: 14.4124 - val_acc: 0.0400\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/159 [============================>.] - ETA: 0s - loss: 4.3566 - acc: 0.0625Epoch 00056: val_loss improved from 14.41238 to 14.40432, saving model to ./tmp/weights.56.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.3571 - acc: 0.0626 - val_loss: 14.4043 - val_acc: 0.0400\n",
      "Epoch 58/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.3207 - acc: 0.0742Epoch 00057: val_loss improved from 14.40432 to 14.36235, saving model to ./tmp/weights.57.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.3207 - acc: 0.0742 - val_loss: 14.3624 - val_acc: 0.0400\n",
      "Epoch 59/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.3228 - acc: 0.0733Epoch 00058: val_loss improved from 14.36235 to 14.33987, saving model to ./tmp/weights.58.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.3229 - acc: 0.0734 - val_loss: 14.3399 - val_acc: 0.0400\n",
      "Epoch 60/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.3131 - acc: 0.0708Epoch 00059: val_loss improved from 14.33987 to 14.33131, saving model to ./tmp/weights.59.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.3138 - acc: 0.0709 - val_loss: 14.3313 - val_acc: 0.0400\n",
      "Epoch 61/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.3043 - acc: 0.0702Epoch 00060: val_loss improved from 14.33131 to 14.14506, saving model to ./tmp/weights.60.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.3042 - acc: 0.0705 - val_loss: 14.1451 - val_acc: 0.0400\n",
      "Epoch 62/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2918 - acc: 0.0771Epoch 00061: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.2926 - acc: 0.0771 - val_loss: 14.1694 - val_acc: 0.0400\n",
      "Epoch 63/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2867 - acc: 0.0772Epoch 00062: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.2858 - acc: 0.0774 - val_loss: 14.1593 - val_acc: 0.0400\n",
      "Epoch 64/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2732 - acc: 0.0808Epoch 00063: val_loss improved from 14.14506 to 14.14048, saving model to ./tmp/weights.63.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.2736 - acc: 0.0809 - val_loss: 14.1405 - val_acc: 0.0400\n",
      "Epoch 65/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2750 - acc: 0.0745Epoch 00064: val_loss improved from 14.14048 to 14.01498, saving model to ./tmp/weights.64.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.2757 - acc: 0.0744 - val_loss: 14.0150 - val_acc: 0.0400\n",
      "Epoch 66/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2416 - acc: 0.0818Epoch 00065: val_loss improved from 14.01498 to 13.97715, saving model to ./tmp/weights.65.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.2415 - acc: 0.0819 - val_loss: 13.9771 - val_acc: 0.0600\n",
      "Epoch 67/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2496 - acc: 0.0788Epoch 00066: val_loss improved from 13.97715 to 13.93924, saving model to ./tmp/weights.66.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.2498 - acc: 0.0786 - val_loss: 13.9392 - val_acc: 0.0500\n",
      "Epoch 68/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2176 - acc: 0.0903Epoch 00067: val_loss improved from 13.93924 to 13.89545, saving model to ./tmp/weights.67.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.2171 - acc: 0.0907 - val_loss: 13.8955 - val_acc: 0.0500\n",
      "Epoch 69/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2321 - acc: 0.0822Epoch 00068: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.2319 - acc: 0.0823 - val_loss: 13.9218 - val_acc: 0.0500\n",
      "Epoch 70/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2184 - acc: 0.0854Epoch 00069: val_loss did not improve\n",
      "159/159 [==============================] - 51s - loss: 4.2183 - acc: 0.0855 - val_loss: 13.9377 - val_acc: 0.0600\n",
      "Epoch 71/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.1915 - acc: 0.0898Epoch 00070: val_loss improved from 13.89545 to 13.87941, saving model to ./tmp/weights.70.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.1913 - acc: 0.0895 - val_loss: 13.8794 - val_acc: 0.0700\n",
      "Epoch 72/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.2001 - acc: 0.0877Epoch 00071: val_loss improved from 13.87941 to 13.83495, saving model to ./tmp/weights.71.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.1985 - acc: 0.0881 - val_loss: 13.8350 - val_acc: 0.0500\n",
      "Epoch 73/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.1736 - acc: 0.0933Epoch 00072: val_loss improved from 13.83495 to 13.82676, saving model to ./tmp/weights.72.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.1728 - acc: 0.0936 - val_loss: 13.8268 - val_acc: 0.0600\n",
      "Epoch 74/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.1803 - acc: 0.0892Epoch 00073: val_loss improved from 13.82676 to 13.81804, saving model to ./tmp/weights.73.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.1808 - acc: 0.0890 - val_loss: 13.8180 - val_acc: 0.0600\n",
      "Epoch 75/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.1589 - acc: 0.0926Epoch 00074: val_loss improved from 13.81804 to 13.76977, saving model to ./tmp/weights.74.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.1595 - acc: 0.0925 - val_loss: 13.7698 - val_acc: 0.0700\n",
      "Epoch 76/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.1552 - acc: 0.0944Epoch 00075: val_loss improved from 13.76977 to 13.67457, saving model to ./tmp/weights.75.hdf5\n",
      "159/159 [==============================] - 51s - loss: 4.1552 - acc: 0.0944 - val_loss: 13.6746 - val_acc: 0.0700\n",
      "Epoch 77/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.1519 - acc: 0.0931Epoch 00076: val_loss did not improve\n",
      "159/159 [==============================] - 51s - loss: 4.1525 - acc: 0.0930 - val_loss: 13.7199 - val_acc: 0.0500\n",
      "Epoch 78/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.1223 - acc: 0.0966Epoch 00077: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.1222 - acc: 0.0970 - val_loss: 13.7350 - val_acc: 0.0800\n",
      "Epoch 79/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.1329 - acc: 0.0959Epoch 00078: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.1321 - acc: 0.0966 - val_loss: 13.7710 - val_acc: 0.0800\n",
      "Epoch 80/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.1036 - acc: 0.1002Epoch 00079: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.1047 - acc: 0.1001 - val_loss: 13.7382 - val_acc: 0.0800\n",
      "Epoch 81/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0941 - acc: 0.1027Epoch 00080: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.0946 - acc: 0.1026 - val_loss: 13.7746 - val_acc: 0.0800\n",
      "Epoch 82/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0886 - acc: 0.1070Epoch 00081: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.0885 - acc: 0.1073 - val_loss: 13.6764 - val_acc: 0.0900\n",
      "Epoch 83/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0777 - acc: 0.1087Epoch 00082: val_loss improved from 13.67457 to 13.66688, saving model to ./tmp/weights.82.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.0779 - acc: 0.1081 - val_loss: 13.6669 - val_acc: 0.0800\n",
      "Epoch 84/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0794 - acc: 0.1039Epoch 00083: val_loss improved from 13.66688 to 13.63064, saving model to ./tmp/weights.83.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.0789 - acc: 0.1041 - val_loss: 13.6306 - val_acc: 0.0800\n",
      "Epoch 85/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0480 - acc: 0.1065Epoch 00084: val_loss improved from 13.63064 to 13.62716, saving model to ./tmp/weights.84.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.0483 - acc: 0.1062 - val_loss: 13.6272 - val_acc: 0.0800\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/159 [============================>.] - ETA: 0s - loss: 4.0362 - acc: 0.1091Epoch 00085: val_loss improved from 13.62716 to 13.56419, saving model to ./tmp/weights.85.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.0355 - acc: 0.1096 - val_loss: 13.5642 - val_acc: 0.0800\n",
      "Epoch 87/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0408 - acc: 0.1043Epoch 00086: val_loss improved from 13.56419 to 13.54011, saving model to ./tmp/weights.86.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.0419 - acc: 0.1040 - val_loss: 13.5401 - val_acc: 0.0900\n",
      "Epoch 88/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0341 - acc: 0.1081Epoch 00087: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 4.0326 - acc: 0.1084 - val_loss: 13.5762 - val_acc: 0.0900\n",
      "Epoch 89/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0142 - acc: 0.1124Epoch 00088: val_loss improved from 13.54011 to 13.52687, saving model to ./tmp/weights.88.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.0139 - acc: 0.1125 - val_loss: 13.5269 - val_acc: 0.0900\n",
      "Epoch 90/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0140 - acc: 0.1141Epoch 00089: val_loss improved from 13.52687 to 13.44452, saving model to ./tmp/weights.89.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.0142 - acc: 0.1140 - val_loss: 13.4445 - val_acc: 0.0900\n",
      "Epoch 91/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 4.0016 - acc: 0.1113Epoch 00090: val_loss improved from 13.44452 to 13.40829, saving model to ./tmp/weights.90.hdf5\n",
      "159/159 [==============================] - 52s - loss: 4.0016 - acc: 0.1116 - val_loss: 13.4083 - val_acc: 0.0900\n",
      "Epoch 92/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9850 - acc: 0.1139Epoch 00091: val_loss improved from 13.40829 to 13.30490, saving model to ./tmp/weights.91.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.9861 - acc: 0.1136 - val_loss: 13.3049 - val_acc: 0.0900\n",
      "Epoch 93/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9716 - acc: 0.1177Epoch 00092: val_loss did not improve\n",
      "159/159 [==============================] - 51s - loss: 3.9708 - acc: 0.1179 - val_loss: 13.3051 - val_acc: 0.0900\n",
      "Epoch 94/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9918 - acc: 0.1161Epoch 00093: val_loss improved from 13.30490 to 13.19211, saving model to ./tmp/weights.93.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.9923 - acc: 0.1158 - val_loss: 13.1921 - val_acc: 0.0900\n",
      "Epoch 95/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9550 - acc: 0.1185Epoch 00094: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.9552 - acc: 0.1185 - val_loss: 13.2140 - val_acc: 0.0900\n",
      "Epoch 96/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9504 - acc: 0.1196Epoch 00095: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.9506 - acc: 0.1200 - val_loss: 13.2681 - val_acc: 0.0900\n",
      "Epoch 97/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9360 - acc: 0.1255Epoch 00096: val_loss improved from 13.19211 to 13.03231, saving model to ./tmp/weights.96.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.9361 - acc: 0.1253 - val_loss: 13.0323 - val_acc: 0.0900\n",
      "Epoch 98/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9439 - acc: 0.1180Epoch 00097: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.9439 - acc: 0.1185 - val_loss: 13.0355 - val_acc: 0.1000\n",
      "Epoch 99/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9237 - acc: 0.1266Epoch 00098: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.9235 - acc: 0.1265 - val_loss: 13.0664 - val_acc: 0.0900\n",
      "Epoch 100/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9029 - acc: 0.1315Epoch 00099: val_loss improved from 13.03231 to 13.00226, saving model to ./tmp/weights.99.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.9030 - acc: 0.1313 - val_loss: 13.0023 - val_acc: 0.1000\n",
      "Epoch 101/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.9056 - acc: 0.1290Epoch 00100: val_loss did not improve\n",
      "159/159 [==============================] - 51s - loss: 3.9045 - acc: 0.1293 - val_loss: 13.0401 - val_acc: 0.0900\n",
      "Epoch 102/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8940 - acc: 0.1324Epoch 00101: val_loss improved from 13.00226 to 12.81726, saving model to ./tmp/weights.101.hdf5\n",
      "159/159 [==============================] - 51s - loss: 3.8945 - acc: 0.1320 - val_loss: 12.8173 - val_acc: 0.1100\n",
      "Epoch 103/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8866 - acc: 0.1309Epoch 00102: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.8871 - acc: 0.1309 - val_loss: 12.8275 - val_acc: 0.1100\n",
      "Epoch 104/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8828 - acc: 0.1323Epoch 00103: val_loss improved from 12.81726 to 12.77809, saving model to ./tmp/weights.103.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.8832 - acc: 0.1322 - val_loss: 12.7781 - val_acc: 0.1000\n",
      "Epoch 105/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8596 - acc: 0.1324Epoch 00104: val_loss improved from 12.77809 to 12.72063, saving model to ./tmp/weights.104.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.8594 - acc: 0.1323 - val_loss: 12.7206 - val_acc: 0.0900\n",
      "Epoch 106/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8692 - acc: 0.1332Epoch 00105: val_loss improved from 12.72063 to 12.64715, saving model to ./tmp/weights.105.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.8695 - acc: 0.1332 - val_loss: 12.6471 - val_acc: 0.1200\n",
      "Epoch 107/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8415 - acc: 0.1405Epoch 00106: val_loss improved from 12.64715 to 12.60570, saving model to ./tmp/weights.106.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.8414 - acc: 0.1404 - val_loss: 12.6057 - val_acc: 0.1100\n",
      "Epoch 108/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8342 - acc: 0.1408Epoch 00107: val_loss improved from 12.60570 to 12.55974, saving model to ./tmp/weights.107.hdf5\n",
      "159/159 [==============================] - 50s - loss: 3.8327 - acc: 0.1414 - val_loss: 12.5597 - val_acc: 0.1100\n",
      "Epoch 109/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8420 - acc: 0.1376Epoch 00108: val_loss improved from 12.55974 to 12.49761, saving model to ./tmp/weights.108.hdf5\n",
      "159/159 [==============================] - 51s - loss: 3.8408 - acc: 0.1377 - val_loss: 12.4976 - val_acc: 0.1100\n",
      "Epoch 110/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8283 - acc: 0.1378Epoch 00109: val_loss improved from 12.49761 to 12.47466, saving model to ./tmp/weights.109.hdf5\n",
      "159/159 [==============================] - 51s - loss: 3.8277 - acc: 0.1378 - val_loss: 12.4747 - val_acc: 0.1100\n",
      "Epoch 111/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.8223 - acc: 0.1414Epoch 00110: val_loss improved from 12.47466 to 12.40739, saving model to ./tmp/weights.110.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.8212 - acc: 0.1417 - val_loss: 12.4074 - val_acc: 0.1100\n",
      "Epoch 112/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7950 - acc: 0.1467Epoch 00111: val_loss improved from 12.40739 to 12.30714, saving model to ./tmp/weights.111.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.7964 - acc: 0.1464 - val_loss: 12.3071 - val_acc: 0.1200\n",
      "Epoch 113/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7844 - acc: 0.1475Epoch 00112: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.7855 - acc: 0.1475 - val_loss: 12.3387 - val_acc: 0.1100\n",
      "Epoch 114/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7911 - acc: 0.1421Epoch 00113: val_loss improved from 12.30714 to 12.21527, saving model to ./tmp/weights.113.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 52s - loss: 3.7895 - acc: 0.1421 - val_loss: 12.2153 - val_acc: 0.1300\n",
      "Epoch 115/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7885 - acc: 0.1470Epoch 00114: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.7886 - acc: 0.1468 - val_loss: 12.2911 - val_acc: 0.1200\n",
      "Epoch 116/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7615 - acc: 0.1490Epoch 00115: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.7612 - acc: 0.1494 - val_loss: 12.2500 - val_acc: 0.1200\n",
      "Epoch 117/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7718 - acc: 0.1467Epoch 00116: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.7712 - acc: 0.1471 - val_loss: 12.2570 - val_acc: 0.1100\n",
      "Epoch 118/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7596 - acc: 0.1496Epoch 00117: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.7597 - acc: 0.1496 - val_loss: 12.2240 - val_acc: 0.1200\n",
      "Epoch 119/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7334 - acc: 0.1508Epoch 00118: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.7346 - acc: 0.1504 - val_loss: 12.2284 - val_acc: 0.1300\n",
      "Epoch 120/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7439 - acc: 0.1515Epoch 00119: val_loss improved from 12.21527 to 12.11534, saving model to ./tmp/weights.119.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.7434 - acc: 0.1515 - val_loss: 12.1153 - val_acc: 0.1300\n",
      "Epoch 121/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7217 - acc: 0.1523Epoch 00120: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.7225 - acc: 0.1523 - val_loss: 12.1396 - val_acc: 0.1400\n",
      "Epoch 122/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.7392 - acc: 0.1505Epoch 00121: val_loss improved from 12.11534 to 12.10321, saving model to ./tmp/weights.121.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.7385 - acc: 0.1504 - val_loss: 12.1032 - val_acc: 0.1200\n",
      "Epoch 123/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6992 - acc: 0.1642Epoch 00122: val_loss improved from 12.10321 to 12.09046, saving model to ./tmp/weights.122.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.6995 - acc: 0.1641 - val_loss: 12.0905 - val_acc: 0.1400\n",
      "Epoch 124/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6974 - acc: 0.1602Epoch 00123: val_loss improved from 12.09046 to 11.99857, saving model to ./tmp/weights.123.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.6970 - acc: 0.1602 - val_loss: 11.9986 - val_acc: 0.1400\n",
      "Epoch 125/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6851 - acc: 0.1580Epoch 00124: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.6844 - acc: 0.1584 - val_loss: 12.0739 - val_acc: 0.1300\n",
      "Epoch 126/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6760 - acc: 0.1550Epoch 00125: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.6760 - acc: 0.1548 - val_loss: 12.0192 - val_acc: 0.1500\n",
      "Epoch 127/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6733 - acc: 0.1605Epoch 00126: val_loss improved from 11.99857 to 11.94827, saving model to ./tmp/weights.126.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.6734 - acc: 0.1606 - val_loss: 11.9483 - val_acc: 0.1400\n",
      "Epoch 128/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6597 - acc: 0.1628Epoch 00127: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.6598 - acc: 0.1628 - val_loss: 11.9873 - val_acc: 0.1500\n",
      "Epoch 129/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6682 - acc: 0.1638Epoch 00128: val_loss improved from 11.94827 to 11.90443, saving model to ./tmp/weights.128.hdf5\n",
      "159/159 [==============================] - 51s - loss: 3.6669 - acc: 0.1643 - val_loss: 11.9044 - val_acc: 0.1500\n",
      "Epoch 130/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6653 - acc: 0.1624Epoch 00129: val_loss improved from 11.90443 to 11.87925, saving model to ./tmp/weights.129.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.6642 - acc: 0.1630 - val_loss: 11.8793 - val_acc: 0.1300\n",
      "Epoch 131/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6277 - acc: 0.1714Epoch 00130: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.6265 - acc: 0.1712 - val_loss: 11.9047 - val_acc: 0.1400\n",
      "Epoch 132/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6439 - acc: 0.1659Epoch 00131: val_loss improved from 11.87925 to 11.81037, saving model to ./tmp/weights.131.hdf5\n",
      "159/159 [==============================] - 52s - loss: 3.6436 - acc: 0.1661 - val_loss: 11.8104 - val_acc: 0.1500\n",
      "Epoch 133/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6136 - acc: 0.1717Epoch 00132: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.6150 - acc: 0.1714 - val_loss: 11.8504 - val_acc: 0.1600\n",
      "Epoch 134/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6234 - acc: 0.1756Epoch 00133: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.6219 - acc: 0.1760 - val_loss: 11.8664 - val_acc: 0.1700\n",
      "Epoch 135/1000\n",
      "158/159 [============================>.] - ETA: 0s - loss: 3.6029 - acc: 0.1774Epoch 00134: val_loss did not improve\n",
      "159/159 [==============================] - 52s - loss: 3.6036 - acc: 0.1771 - val_loss: 11.9018 - val_acc: 0.1700\n",
      "Epoch 136/1000\n",
      " 20/159 [==>...........................] - ETA: 43s - loss: 3.5348 - acc: 0.1719"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow(X, y, batch_size=batch_size)\n",
    "\n",
    "# fine-tune the model\n",
    "checkpointer = ModelCheckpoint(filepath='./tmp/weights.{epoch:02d}.hdf5', verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer],\n",
    "    validation_data = (X[:100], y[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not train_model:\n",
    "    model = load_model('./tmp/weights.49.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_to_index = train_generator.class_indices\n",
    "index_to_class = {i:c for c,i in class_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for img_path in os.listdir(test_data_dir):\n",
    "    predictions = list(get_predictions(test_data_dir + img_path))\n",
    "    predictions.insert(0, img_path.split(\".\")[0])\n",
    "    rows.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_rows = []\n",
    "for r in rows:\n",
    "    predictions = list(r[1])\n",
    "    predictions.insert(0, r[0])\n",
    "    clean_rows.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(clean_rows, columns=['id'] + list(class_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"test_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
