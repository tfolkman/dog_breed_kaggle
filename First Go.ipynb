{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import pandas as pd\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_data_folders = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = '/media/tyler/slowdata/models/keras_vgg_16'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = '/home/tyler/data/kaggle/dog_breed/train/'\n",
    "ordered_train_folder = \"/home/tyler/data/kaggle/dog_breed/train_ordered/\"\n",
    "test_data_dir = '/home/tyler/data/kaggle/dog_breed/test/'\n",
    "labels = '/home/tyler/data/kaggle/dog_breed/labels.csv'\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "nb_train_samples = 10222\n",
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False,\n",
    "                          input_shape=(img_width, img_height, 3), classes=120)\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(120, activation='softmax'))\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 120)               6453624   \n",
      "=================================================================\n",
      "Total params: 21,168,312\n",
      "Trainable params: 6,453,624\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 classes\n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_csv(labels)\n",
    "n_classes = len(class_names)\n",
    "print(\"{} classes\".format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if create_data_folders:\n",
    "    created_folder_names = []\n",
    "    for train_img_tuple in labels_df.values:\n",
    "        file_name = train_img_tuple[0] + \".jpg\"\n",
    "        label_value = train_img_tuple[1]\n",
    "        if label_value not in created_folder_names:\n",
    "            created_folder_names.append(label_value)\n",
    "            os.mkdir(ordered_train_folder + label_value)\n",
    "        copyfile(train_data_dir + file_name, ordered_train_folder + label_value\n",
    "                 + \"/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10222 images belonging to 120 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=50, callbacks=[<keras.ca..., steps_per_epoch=638)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.8084 - acc: 0.0079Epoch 00000: saving model to ./tmp/weights.00.hdf5\n",
      "638/638 [==============================] - 81s - loss: 4.8083 - acc: 0.0080    \n",
      "Epoch 2/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7876 - acc: 0.0118Epoch 00001: saving model to ./tmp/weights.01.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7876 - acc: 0.0118    \n",
      "Epoch 3/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7861 - acc: 0.0113Epoch 00002: saving model to ./tmp/weights.02.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7861 - acc: 0.0113    \n",
      "Epoch 4/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7839 - acc: 0.0121Epoch 00003: saving model to ./tmp/weights.03.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7839 - acc: 0.0120    \n",
      "Epoch 5/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7808 - acc: 0.0124Epoch 00004: saving model to ./tmp/weights.04.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7807 - acc: 0.0124    \n",
      "Epoch 6/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7755 - acc: 0.0128Epoch 00005: saving model to ./tmp/weights.05.hdf5\n",
      "638/638 [==============================] - 78s - loss: 4.7755 - acc: 0.0128    \n",
      "Epoch 7/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7728 - acc: 0.0143Epoch 00006: saving model to ./tmp/weights.06.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7728 - acc: 0.0143    \n",
      "Epoch 8/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7692 - acc: 0.0124Epoch 00007: saving model to ./tmp/weights.07.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7690 - acc: 0.0125    \n",
      "Epoch 9/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7631 - acc: 0.0152Epoch 00008: saving model to ./tmp/weights.08.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7630 - acc: 0.0152    \n",
      "Epoch 10/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7569 - acc: 0.0158Epoch 00009: saving model to ./tmp/weights.09.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7569 - acc: 0.0159    \n",
      "Epoch 11/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7511 - acc: 0.0176Epoch 00010: saving model to ./tmp/weights.10.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7511 - acc: 0.0175    \n",
      "Epoch 12/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7425 - acc: 0.0180Epoch 00011: saving model to ./tmp/weights.11.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7425 - acc: 0.0179    \n",
      "Epoch 13/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7333 - acc: 0.0178Epoch 00012: saving model to ./tmp/weights.12.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7334 - acc: 0.0177    \n",
      "Epoch 14/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7271 - acc: 0.0203Epoch 00013: saving model to ./tmp/weights.13.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7272 - acc: 0.0203    \n",
      "Epoch 15/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7183 - acc: 0.0200Epoch 00014: saving model to ./tmp/weights.14.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7185 - acc: 0.0201    \n",
      "Epoch 16/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.7044 - acc: 0.0229Epoch 00015: saving model to ./tmp/weights.15.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.7041 - acc: 0.0229    \n",
      "Epoch 17/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.6915 - acc: 0.0251Epoch 00016: saving model to ./tmp/weights.16.hdf5\n",
      "638/638 [==============================] - 78s - loss: 4.6915 - acc: 0.0252    \n",
      "Epoch 18/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.6859 - acc: 0.0243Epoch 00017: saving model to ./tmp/weights.17.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.6859 - acc: 0.0243    \n",
      "Epoch 19/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.6693 - acc: 0.0275Epoch 00018: saving model to ./tmp/weights.18.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.6685 - acc: 0.0275    \n",
      "Epoch 20/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.6555 - acc: 0.0245Epoch 00019: saving model to ./tmp/weights.19.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.6552 - acc: 0.0246    \n",
      "Epoch 21/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.6427 - acc: 0.0271Epoch 00020: saving model to ./tmp/weights.20.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.6427 - acc: 0.0271    \n",
      "Epoch 22/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.6256 - acc: 0.0306Epoch 00021: saving model to ./tmp/weights.21.hdf5\n",
      "638/638 [==============================] - 77s - loss: 4.6258 - acc: 0.0306    \n",
      "Epoch 23/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.6071 - acc: 0.0325Epoch 00022: saving model to ./tmp/weights.22.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.6071 - acc: 0.0324    \n",
      "Epoch 24/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.5924 - acc: 0.0338Epoch 00023: saving model to ./tmp/weights.23.hdf5\n",
      "638/638 [==============================] - 78s - loss: 4.5924 - acc: 0.0337    \n",
      "Epoch 25/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.5611 - acc: 0.0345- ETA: 0s - loss: 4.5602 - acc: 0.Epoch 00024: saving model to ./tmp/weights.24.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.5611 - acc: 0.0347    \n",
      "Epoch 26/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.5508 - acc: 0.0374Epoch 00025: saving model to ./tmp/weights.25.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.5508 - acc: 0.0374    \n",
      "Epoch 27/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.5270 - acc: 0.0425Epoch 00026: saving model to ./tmp/weights.26.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.5268 - acc: 0.0425    \n",
      "Epoch 28/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.5139 - acc: 0.0407Epoch 00027: saving model to ./tmp/weights.27.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.5140 - acc: 0.0407    \n",
      "Epoch 29/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.4874 - acc: 0.0443Epoch 00028: saving model to ./tmp/weights.28.hdf5\n",
      "638/638 [==============================] - 78s - loss: 4.4875 - acc: 0.0443    \n",
      "Epoch 30/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.4662 - acc: 0.0448Epoch 00029: saving model to ./tmp/weights.29.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.4658 - acc: 0.0449    \n",
      "Epoch 31/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.4561 - acc: 0.0496Epoch 00030: saving model to ./tmp/weights.30.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.4562 - acc: 0.0495    \n",
      "Epoch 32/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.4326 - acc: 0.0468Epoch 00031: saving model to ./tmp/weights.31.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.4319 - acc: 0.0471    \n",
      "Epoch 33/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.4125 - acc: 0.0525Epoch 00032: saving model to ./tmp/weights.32.hdf5\n",
      "638/638 [==============================] - 78s - loss: 4.4121 - acc: 0.0526    \n",
      "Epoch 34/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.3747 - acc: 0.0556Epoch 00033: saving model to ./tmp/weights.33.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.3749 - acc: 0.0557    \n",
      "Epoch 35/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.3665 - acc: 0.0524Epoch 00034: saving model to ./tmp/weights.34.hdf5\n",
      "638/638 [==============================] - 78s - loss: 4.3665 - acc: 0.0524    \n",
      "Epoch 36/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.3410 - acc: 0.0599Epoch 00035: saving model to ./tmp/weights.35.hdf5\n",
      "638/638 [==============================] - 78s - loss: 4.3411 - acc: 0.0598    \n",
      "Epoch 37/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.3107 - acc: 0.0640Epoch 00036: saving model to ./tmp/weights.36.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 77s - loss: 4.3106 - acc: 0.0640    \n",
      "Epoch 38/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.2855 - acc: 0.0668Epoch 00037: saving model to ./tmp/weights.37.hdf5\n",
      "638/638 [==============================] - 77s - loss: 4.2857 - acc: 0.0670    \n",
      "Epoch 39/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.2699 - acc: 0.0659Epoch 00038: saving model to ./tmp/weights.38.hdf5\n",
      "638/638 [==============================] - 78s - loss: 4.2704 - acc: 0.0659    \n",
      "Epoch 40/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.2565 - acc: 0.0668Epoch 00039: saving model to ./tmp/weights.39.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.2562 - acc: 0.0667    \n",
      "Epoch 41/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.2372 - acc: 0.0671Epoch 00040: saving model to ./tmp/weights.40.hdf5\n",
      "638/638 [==============================] - 78s - loss: 4.2376 - acc: 0.0670    \n",
      "Epoch 42/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.2072 - acc: 0.0776Epoch 00041: saving model to ./tmp/weights.41.hdf5\n",
      "638/638 [==============================] - 80s - loss: 4.2073 - acc: 0.0775    \n",
      "Epoch 43/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.1734 - acc: 0.0768Epoch 00042: saving model to ./tmp/weights.42.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.1740 - acc: 0.0768    \n",
      "Epoch 44/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.1592 - acc: 0.0796Epoch 00043: saving model to ./tmp/weights.43.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.1589 - acc: 0.0797    \n",
      "Epoch 45/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.1414 - acc: 0.0830Epoch 00044: saving model to ./tmp/weights.44.hdf5\n",
      "638/638 [==============================] - 80s - loss: 4.1415 - acc: 0.0829    \n",
      "Epoch 46/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.1195 - acc: 0.0805Epoch 00045: saving model to ./tmp/weights.45.hdf5\n",
      "638/638 [==============================] - 80s - loss: 4.1202 - acc: 0.0805    \n",
      "Epoch 47/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.1066 - acc: 0.0824Epoch 00046: saving model to ./tmp/weights.46.hdf5\n",
      "638/638 [==============================] - 80s - loss: 4.1061 - acc: 0.0828    \n",
      "Epoch 48/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.0887 - acc: 0.0876Epoch 00047: saving model to ./tmp/weights.47.hdf5\n",
      "638/638 [==============================] - 80s - loss: 4.0886 - acc: 0.0877    \n",
      "Epoch 49/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.0562 - acc: 0.0947Epoch 00048: saving model to ./tmp/weights.48.hdf5\n",
      "638/638 [==============================] - 79s - loss: 4.0561 - acc: 0.0945    \n",
      "Epoch 50/50\n",
      "637/638 [============================>.] - ETA: 0s - loss: 4.0450 - acc: 0.0970Epoch 00049: saving model to ./tmp/weights.49.hdf5\n",
      "638/638 [==============================] - 80s - loss: 4.0447 - acc: 0.0969    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb6068b3588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    ordered_train_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "\n",
    "# fine-tune the model\n",
    "checkpointer = ModelCheckpoint(filepath='./tmp/weights.{epoch:02d}.hdf5', verbose=1)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not train_model:\n",
    "    model = load_model('./tmp/weights.49.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_to_index = train_generator.class_indices\n",
    "index_to_class = {i:c for c,i in class_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for img_path in os.listdir(test_data_dir):\n",
    "    predictions = list(get_predictions(test_data_dir + img_path))\n",
    "    predictions.insert(0, img_path.split(\".\")[0])\n",
    "    rows.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rows = []\n",
    "for r in rows:\n",
    "    predictions = list(r[1])\n",
    "    predictions.insert(0, r[0])\n",
    "    clean_rows.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(clean_rows, columns=['id'] + list(class_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
